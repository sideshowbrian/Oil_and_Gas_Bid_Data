{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First bring in the csv files and drop them into a sqlite databse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3                     #Bring in Sqlite for the database\n",
    "from os import listdir             #Bring in OS to read all the files\n",
    "from os.path import isfile, join  \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the latest fracfocus data from http://fracfocus.org/data-download.  Download the csv files and save the unzipped files to your computer.  Then update 'mypath' below to that location.\n",
    "\n",
    "The program then loops throught the file names in the folder then saves them to 2 lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypath = \"C:/Users/BWeaver/Google Drive/FracFocus/FracFocus\"  #make sure the use forward slashes or double '\\\\'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "FracFocusRegistry_files = list()\n",
    "registryupload_files = list()\n",
    "\n",
    "for file in onlyfiles:\n",
    "    if file[:17] == 'FracFocusRegistry':\n",
    "        FracFocusRegistry_files.append(file)\n",
    "    elif file[:4] == 'regi':\n",
    "        registryupload_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will then build the SQLite database if the file isn't there.  If it is then delete the FracFocusRegistry and registryupload tables.  \n",
    "\n",
    "Then rebuild them with all the correct headers.  This was taken from the headers of the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x90e3c00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(mypath + '/FracFocus.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "DROP TABLE IF EXISTS FracFocusRegistry;\n",
    "''')\n",
    "cur.execute('''\n",
    "CREATE TABLE FracFocusRegistry (\n",
    "    pKey TEXT NOT NULL PRIMARY KEY,\n",
    "    JobStartDate              NUMERIC,\n",
    "    JobEndDate                NUMERIC,\n",
    "    APINumber                 TEXT,\n",
    "    StateNumber               NUMERIC,\n",
    "    CountyNumber              NUMERIC,\n",
    "    OperatorName              TEXT,\n",
    "    WellName                  TEXT,\n",
    "    Latitude                  TEXT,\n",
    "    Longitude                 TEXT,\n",
    "    Projection                TEXT,\n",
    "    TVD                       TEXT,\n",
    "    TotalBaseWaterVolume      TEXT,\n",
    "    TotalBaseNonWaterVolume   TEXT,\n",
    "    StateName                 TEXT,\n",
    "    CountyName                TEXT,\n",
    "    FFVersion                 TEXT,\n",
    "    FederalWell               TEXT,\n",
    "    IndianWell                TEXT,\n",
    "    Source                    TEXT,\n",
    "    DTMOD                     TEXT,\n",
    "    PurposeKey                TEXT,\n",
    "    TradeName                 TEXT,\n",
    "    Supplier                  TEXT,\n",
    "    Purpose                   TEXT,\n",
    "    SystemApproach            TEXT,\n",
    "    IsWater                   TEXT,\n",
    "    PurposePercentHFJob       TEXT,\n",
    "    PurposeIngredientMSDS     TEXT,\n",
    "    IngredientKey             TEXT,\n",
    "    IngredientName            TEXT,\n",
    "    CASNumber                 TEXT,\n",
    "    PercentHighAdditive       TEXT,\n",
    "    PercentHFJob              TEXT,\n",
    "    IngredientComment         TEXT,\n",
    "    IngredientMSDS            TEXT,\n",
    "    MassIngredient            TEXT,\n",
    "    ClaimantCompany           TEXT,\n",
    "    DisclosureKey             TEXT\n",
    "    \n",
    ");\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "DROP TABLE IF EXISTS registryupload;\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE registryupload (\n",
    "    pKey                      TEXT NOT NULL PRIMARY KEY,\n",
    "    JobStartDate              NUMERIC,\n",
    "    JobEndDate                NUMERIC,\n",
    "    APINumber                 TEXT,\n",
    "    StateNumber               NUMERIC,\n",
    "    CountyNumber              NUMERIC,\n",
    "    OperatorName              TEXT,\n",
    "    WellName                  TEXT,\n",
    "    Latitude                  TEXT,\n",
    "    Longitude                 TEXT,\n",
    "    Projection                TEXT,\n",
    "    TVD                       TEXT,\n",
    "    TotalBaseWaterVolume      TEXT,\n",
    "    TotalBaseNonWaterVolume   TEXT,\n",
    "    StateName                 TEXT,\n",
    "    CountyName                TEXT,\n",
    "    FFVersion                 TEXT,\n",
    "    FederalWell               TEXT,\n",
    "    IndianWell                TEXT,\n",
    "    Source                    TEXT,\n",
    "    DTMOD                     TEXT\n",
    ");\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the database is built we'll start loading it with data from the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_1.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_10.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_11.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_12.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_13.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_2.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_3.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_4.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_5.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_6.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_7.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_8.csv\n",
      "\n",
      "C:/Users/BWeaver/Google Drive/FracFocus/FracFocus/FracFocusRegistry_9.csv\n"
     ]
    }
   ],
   "source": [
    "for file in FracFocusRegistry_files:\n",
    "    #fhand = pd.read(mypath + '/' + file, nrows=10)\n",
    "    print('\\n' + mypath + '/' + file)\n",
    "    \n",
    "    #read file with Pandas\n",
    "    fhand = pd.read_csv(mypath + '/' + file, nrows=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to iterate through the CSV file in chunks and store the data into sqllite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'FracFocusRegistry_9.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d8e9b2a5ba72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\BWeaver\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\BWeaver\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\BWeaver\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\BWeaver\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\BWeaver\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'FracFocusRegistry_9.csv' does not exist"
     ]
    }
   ],
   "source": [
    "    chunksize = 100000\n",
    "    i = 0\n",
    "    j = 1\n",
    "    for df in pd.read_csv(file, chunksize=chunksize, iterator=True):\n",
    "          df = df.rename(columns={c: c.replace(' ', '') for c in df.columns}) \n",
    "          df.index += j\n",
    "          i+=1\n",
    "          df.to_sql('FracFocusRegistry', 'FracFocus.sqlite', if_exists='append')\n",
    "          j = df.index[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #load the data into the database\n",
    "    cur.execute('''INSERT INTO FracFocusRegistry (pKey, JobStartDate, JobEndDate, APINumber,\n",
    "    StateNumber, CountyNumber, OperatorName, WellName, Latitude, Longitude,\n",
    "    Projection, TVD, TotalBaseWaterVolume, TotalBaseNonWaterVolume, StateName,\n",
    "    CountyName, FFVersion, FederalWell, IndianWell, Source, DTMOD, PurposeKey,\n",
    "    TradeName, Supplier, Purpose, SystemApproach, IsWater, PurposePercentHFJob,\n",
    "    PurposeIngredientMSDS, IngredientKey, IngredientName, CASNumber, PercentHighAdditive,\n",
    "    PercentHFJob, IngredientComment, IngredientMSDS, MassIngredient, ClaimantCompany,\n",
    "    DisclosureKey)\n",
    "        VALUES ( ?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,? )''', ( fhand ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
