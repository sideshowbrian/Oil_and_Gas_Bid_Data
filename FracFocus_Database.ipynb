{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object of this program is loop through the fracfocus CSV files and add them to a SQLite database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we bring in the modules we need for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3                     #Bring in Sqlite for the database\n",
    "\n",
    "from os import listdir             #Bring in OS to read all the files\n",
    "from os.path import isfile, join  \n",
    "\n",
    "import pandas as pd                #Bring in Pandas to work wiht the data\n",
    "\n",
    "import pandas as pd                #Bring in Pandas to work wiht the data\n",
    "import matplotlib.pyplot as plt    #Bring in matplotlib to run visualizations\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np                 #Bring in numpy for math operations\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the latest fracfocus data from http://fracfocus.org/data-download.  Download the csv files and save the unzipped files to your computer.  Then update 'mypath' below to that location.\n",
    "\n",
    "The program then loops throught the file names in the folder then saves them to 2 lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mypath = \"C:/Users/BWeaver/Google Drive/FracFocus/FracFocus\"  #make sure the use back slashes or double forward slashes '\\\\'\n",
    "mypath = '/Users/brianweaver/Documents/GitHub/Oil_and_Gas_Bid_Data/FF_Data'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]   #find files in the directory\n",
    "\n",
    "FracFocusRegistry_files = list()\n",
    "registryupload_files = list()\n",
    "\n",
    "#loop through list of files and add them to the two lists\n",
    "for file in onlyfiles:\n",
    "    if file[:17] == 'FracFocusRegistry':\n",
    "        FracFocusRegistry_files.append(file)\n",
    "    elif file[:14] == 'registryupload':\n",
    "        registryupload_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will then build the SQLite database if the file isn't there.  If the file is there then it will delete the FracFocusRegistry and registryupload tables.  \n",
    "\n",
    "Then rebuild them with all the correct headers.  This was taken from the headers of the csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll crreat a connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(mypath + '/FracFocus.sqlite')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll make sure if the database is already made that the table is cleared out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "DROP TABLE IF EXISTS FracFocusRegistry;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll rebuild the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "CREATE TABLE FracFocusRegistry (\n",
    "    id                        INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    UploadKey                 TEXT,\n",
    "    JobStartDate              NUMERIC,\n",
    "    JobEndDate                NUMERIC,\n",
    "    APINumber                 TEXT,\n",
    "    StateNumber               NUMERIC,\n",
    "    CountyNumber              NUMERIC,\n",
    "    OperatorName              TEXT,\n",
    "    WellName                  TEXT,\n",
    "    Latitude                  TEXT,\n",
    "    Longitude                 TEXT,\n",
    "    Projection                TEXT,\n",
    "    TVD                       TEXT,\n",
    "    TotalBaseWaterVolume      TEXT,\n",
    "    TotalBaseNonWaterVolume   TEXT,\n",
    "    StateName                 TEXT,\n",
    "    CountyName                TEXT,\n",
    "    FFVersion                 TEXT,\n",
    "    FederalWell               TEXT,\n",
    "    IndianWell                TEXT,\n",
    "    Source                    TEXT,\n",
    "    DTMOD                     TEXT,\n",
    "    PurposeKey                TEXT,\n",
    "    TradeName                 TEXT,\n",
    "    Supplier                  TEXT,\n",
    "    Purpose                   TEXT,\n",
    "    SystemApproach            TEXT,\n",
    "    IsWater                   TEXT,\n",
    "    PurposePercentHFJob       TEXT,\n",
    "    PurposeIngredientMSDS     TEXT,\n",
    "    IngredientKey             TEXT,\n",
    "    IngredientName            TEXT,\n",
    "    CASNumber                 TEXT,\n",
    "    PercentHighAdditive       TEXT,\n",
    "    PercentHFJob              TEXT,\n",
    "    IngredientComment         TEXT,\n",
    "    IngredientMSDS            TEXT,\n",
    "    MassIngredient            TEXT,\n",
    "    ClaimantCompany           TEXT,\n",
    "    DisclosureKey             TEXT\n",
    "    \n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll drop the table for the registryupload to make sure it's cleared out for the new upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "DROP TABLE IF EXISTS registryupload;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then rebuild it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "CREATE TABLE registryupload (\n",
    "    id                        INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    pKey                      TEXT,\n",
    "    JobStartDate              NUMERIC,\n",
    "    JobEndDate                NUMERIC,\n",
    "    APINumber                 TEXT,\n",
    "    StateNumber               NUMERIC,\n",
    "    CountyNumber              NUMERIC,\n",
    "    OperatorName              TEXT,\n",
    "    WellName                  TEXT,\n",
    "    Latitude                  TEXT,\n",
    "    Longitude                 TEXT,\n",
    "    Projection                TEXT,\n",
    "    TVD                       TEXT,\n",
    "    TotalBaseWaterVolume      TEXT,\n",
    "    TotalBaseNonWaterVolume   TEXT,\n",
    "    StateName                 TEXT,\n",
    "    CountyName                TEXT,\n",
    "    FFVersion                 TEXT,\n",
    "    FederalWell               TEXT,\n",
    "    IndianWell                TEXT,\n",
    "    Source                    TEXT,\n",
    "    DTMOD                     TEXT\n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the database is built we'll start loading it with data from the csv files.  Starting wiht the FracFocusRegistry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in FracFocusRegistry_files:\n",
    "    print(file)\n",
    "    df = pd.read_csv(mypath + '/' + file)\n",
    "    df.to_sql('FracFocusRegistry', conn, if_exists='append', index=False)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we upload the registryupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in registryupload_files:\n",
    "    print(file)\n",
    "    df = pd.read_csv(mypath + '/' + file)\n",
    "    df.to_sql('registryupload', conn, if_exists='append', index=False)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next close the connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now the Database is setup\n",
    "\n",
    "Let's see what the data looks like.  We'll use SQL to pull the Wyoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wyoming_Data = pd.read_sql_query(\"\"\"SELECT JobStartDate, JobEndDate, APINumber, StateNumber, CountyNumber, OperatorName, \n",
    "                      WellName, Latitude, Longitude, Projection, TVD, TotalBaseWaterVolume, \n",
    "                      TotalBaseNonWaterVolume, StateName, CountyName from registryupload\n",
    "            WHERE     StateNumber = 5 \"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wyoming_Data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at some time series information.  Becuase we just pull this data in we need to format it in order to filter off of it.  \n",
    "\n",
    "First we'll format the date.  Even though it's readable to humans, the program needs it cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wyoming_Data['JobStartDate'] = pd.to_datetime(Wyoming_Data['JobStartDate'])\n",
    "Wyoming_Data['JobEndDate'] = pd.to_datetime(Wyoming_Data['JobEndDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wyoming_Data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()                                    #Setup the plot\n",
    "fig.set_size_inches(10, 7)                                  #Set the figure size\n",
    "plt.style.use('fivethirtyeight')                            #Set the style, I'm a sucker for fivethirtyeight plots\n",
    "#min_x = datetime.strptime('2010-06-01','%Y-%m-%d').date()   #set the Min date on the x-axis \n",
    "#max_x = datetime.strptime('2018-05-01','%Y-%m-%d').date()   #Set the Max date on the x-axis\n",
    "ax.set_xlim(min_x, max_x)\n",
    "ax.hist(Wyoming_Data['JobEndDate'].values, bins = 250)      #Set the Historgram paramaters\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wyoming_Data['OperatorName'].value_counts()[:10].plot(kind='barh', figsize = (7,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
